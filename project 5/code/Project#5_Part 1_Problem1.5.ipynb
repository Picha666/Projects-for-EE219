{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "import pytz\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata_before = ['test_data/sample1_period1.txt','test_data/sample4_period1.txt','test_data/sample5_period1.txt','test_data/sample8_period1.txt']\n",
    "testdata_between = ['test_data/sample2_period2.txt','test_data/sample6_period2.txt','test_data/sample9_period2.txt']\n",
    "testdata_after = ['test_data/sample3_period3.txt','test_data/sample7_period3.txt','test_data/sample10_period3.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = ['tweets_#gohawks.txt', 'tweets_#gopatriots.txt', 'tweets_#nfl.txt', \n",
    "       'tweets_#patriots.txt', 'tweets_#sb49.txt', 'tweets_#superbowl.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "starttime_list = np.zeros(6,int)\n",
    "endtime_list = np.zeros(6,int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets_#gohawks.txt\n",
      "tweets_#gopatriots.txt\n",
      "tweets_#nfl.txt\n",
      "tweets_#patriots.txt\n",
      "tweets_#sb49.txt\n",
      "tweets_#superbowl.txt\n",
      "start_time [1419804875 1420835445 1419999683 1419805279 1421238675 1419866833]\n",
      "end_time [1423304269 1423295675 1423335336 1423335300 1423335336 1423332008]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tag)):\n",
    "    tagname = tag[i]\n",
    "\n",
    "    print(tagname)\n",
    "    f = io.open(tagname, 'rb')\n",
    "    \n",
    "    f.seek(0, 0)\n",
    "    tweet_0 = json.loads(f.readline()) \n",
    "   \n",
    "    f.seek(0, 0) #Go back to the original point\n",
    "    \n",
    "    starttime_list[i] = tweet_0['firstpost_date']\n",
    "    \n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        end_time = tweet['firstpost_date']\n",
    "    endtime_list[i] = end_time\n",
    "print('start_time', starttime_list)\n",
    "print('end_time', endtime_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = min(starttime_list)\n",
    "end_time = max(endtime_list)\n",
    "time_8am = 1422806400\n",
    "time_8pm = 1422849600\n",
    "all_hour_before = math.ceil((time_8am - start_time)/3600.)\n",
    "all_hour_between = math.ceil((time_8pm - time_8am)/3600.)\n",
    "all_hour_after = math.ceil((end_time - time_8am)/3600.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweet_features_before = np.zeros([all_hour_before, 9])\n",
    "all_user_id_before = [[]] * all_hour_before\n",
    "all_tweet_features_between = np.zeros([all_hour_between, 9]) \n",
    "all_user_id_between = [[]] * all_hour_between\n",
    "all_tweet_features_after = np.zeros([all_hour_after, 9])\n",
    "all_user_id_after = [[]] * all_hour_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671942.0\n",
      "2193017.0\n",
      "273864.0\n"
     ]
    }
   ],
   "source": [
    "# aggregate data features\n",
    "for tagname in tag:\n",
    "    f = io.open(tagname, 'r')\n",
    "    \n",
    "    # calculate features for model construction\n",
    "    pst_tz = pytz.timezone('US/Pacific')\n",
    "\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        time = tweet['firstpost_date']\n",
    "        \n",
    "        # For the first time period\n",
    "        if time < 1422806400:\n",
    "            # Calculate which hour current tweet belongs to\n",
    "            n = math.ceil((time - start_time)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "            all_tweet_features_before[(n-1), 0] += 1\n",
    "            all_tweet_features_before[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "            followers = tweet['author']['followers']\n",
    "            all_tweet_features_before[(n-1), 2] += followers\n",
    "            if followers > all_tweet_features_before[(n-1), 3]:\n",
    "                all_tweet_features_before[(n-1), 3] = followers\n",
    "            time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "            all_tweet_features_before[(n-1), 4] = time_of_the_day\n",
    "            all_tweet_features_before[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "            all_tweet_features_before[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "            all_tweet_features_before[(n-1), 7] += tweet['metrics']['impressions']\n",
    "            all_user_id_before[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "            \n",
    "        elif (time >= 1422806400) and (time < 1422849601):\n",
    "            # Calculate which hour current tweet belongs to\n",
    "            n = math.ceil((time - time_8am)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "            all_tweet_features_between[(n-1), 0] += 1\n",
    "            all_tweet_features_between[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "            followers = tweet['author']['followers']\n",
    "            all_tweet_features_between[(n-1), 2] += followers\n",
    "            if followers > all_tweet_features_between[(n-1), 3]:\n",
    "                all_tweet_features_between[(n-1), 3] = followers\n",
    "            time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "            all_tweet_features_between[(n-1), 4] = time_of_the_day\n",
    "            all_tweet_features_between[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "            all_tweet_features_between[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "            all_tweet_features_between[(n-1), 7] += tweet['metrics']['impressions']\n",
    "            all_user_id_between[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "            \n",
    "        else:\n",
    "            # Calculate which hour current tweet belongs to\n",
    "            n = math.ceil((time - time_8pm)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "            all_tweet_features_after[(n-1), 0] += 1\n",
    "            all_tweet_features_after[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "            followers = tweet['author']['followers']\n",
    "            all_tweet_features_after[(n-1), 2] += followers\n",
    "            if followers > all_tweet_features_before[(n-1), 3]:\n",
    "                all_tweet_features_after[(n-1), 3] = followers\n",
    "            time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "            all_tweet_features_after[(n-1), 4] = time_of_the_day\n",
    "            all_tweet_features_after[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "            all_tweet_features_after[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "            all_tweet_features_after[(n-1), 7] += tweet['metrics']['impressions']\n",
    "            all_user_id_after[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "    \n",
    "for t in range(len(all_user_id_before)):\n",
    "    all_tweet_features_before[t, 8] = len(np.unique(all_user_id_before[t]))\n",
    "for l in range(len(all_user_id_between)):\n",
    "    all_tweet_features_between[l, 8] = len(np.unique(all_user_id_between[l]))\n",
    "for n in range(len(all_user_id_after)):\n",
    "    all_tweet_features_after[n, 8] = len(np.unique(all_user_id_after[n]))\n",
    "print(sum(all_tweet_features_before[:, 0]))\n",
    "print(sum(all_tweet_features_between[:, 0]))\n",
    "print(sum(all_tweet_features_after[:, 0]))\n",
    "    \n",
    "    # Reconstruct independent and dependent variable\n",
    "all_tweet_before_y = all_tweet_features_before[1:,0]\n",
    "    #print(tweet_before_y.shape)\n",
    "all_tweet_before_x = all_tweet_features_before[:(all_hour_before-1), 1:]\n",
    "    #print(tweet_before_x.shape)\n",
    "    \n",
    "all_tweet_between_y = all_tweet_features_between[1:,0]\n",
    "    #print(tweet_between_y.shape)\n",
    "all_tweet_between_x = all_tweet_features_between[:(all_hour_between-1), 1:]\n",
    "    #print(tweet_between_x.shape)\n",
    "    \n",
    "all_tweet_after_y = all_tweet_features_after[1:,0]\n",
    "    #print(tweet_after_y.shape)\n",
    "all_tweet_after_x = all_tweet_features_after[:(all_hour_after-1), 1:]\n",
    "    #print(tweet_after_x.shape)\n",
    "                \n",
    "time_series = ['Before Feb. 1, 8:00 a.m.', 'Between Feb. 1, 8:00 a.m. and 8:00 p.m.', 'After Feb. 1, 8:00 p.m.']\n",
    "tweet_y_all = [all_tweet_before_y, all_tweet_between_y, all_tweet_after_y]\n",
    "tweet_x_all = [all_tweet_before_x, all_tweet_between_x, all_tweet_after_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trainset prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#before period\n",
    "tweet_features_before_set_x = []\n",
    "tweet_featuers_before_set_y = all_tweet_features_before[5:,0]\n",
    "\n",
    "for i in range(all_hour_before-5):\n",
    "    tweet_features_before_set_x.append(all_tweet_features_before[i:i+5,1:])\n",
    "tweet_features_before_set_x=np.reshape(tweet_features_before_set_x,(len(tweet_features_before_set_x),40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#between period\n",
    "tweet_features_between_set_x = []\n",
    "tweet_featuers_between_set_y = all_tweet_features_between[5:,0]\n",
    "\n",
    "for i in range(all_hour_between-5):\n",
    "    tweet_features_between_set_x.append(all_tweet_features_between[i:i+5,1:])\n",
    "tweet_features_between_set_x=np.reshape(tweet_features_between_set_x,(len(tweet_features_between_set_x),40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "#after period\n",
    "tweet_features_after_set_x = []\n",
    "tweet_featuers_after_set_y = all_tweet_features_after[5:,0]\n",
    "\n",
    "print(all_hour_after)\n",
    "for i in range(all_hour_after-5):\n",
    "    tweet_features_after_set_x.append(all_tweet_features_after[i:i+5,1:])\n",
    "tweet_features_after_set_x=np.reshape(tweet_features_after_set_x,(len(tweet_features_after_set_x),40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data/sample1_period1.txt\n",
      "test_data/sample4_period1.txt\n",
      "test_data/sample5_period1.txt\n",
      "test_data/sample8_period1.txt\n",
      "start_time [1422554405 1422223204 1422406820 1422489605]\n",
      "end_time [1422575945 1422244781 1422428389 1422507351]\n"
     ]
    }
   ],
   "source": [
    "#gather information of testset\n",
    "start_time_test_before = np.zeros(4,int)\n",
    "end_time_test_before = np.zeros(4,int)\n",
    "for i in range(len(testdata_before)):\n",
    "    tagname = testdata_before[i]\n",
    "\n",
    "    print(tagname)\n",
    "    f = io.open(tagname, 'rb')\n",
    "    \n",
    "    f.seek(0, 0)\n",
    "    tweet_0 = json.loads(f.readline()) \n",
    "   \n",
    "    f.seek(0, 0) #Go back to the original point\n",
    "    \n",
    "    start_time_list_test[i] = tweet_0['firstpost_date']\n",
    "    \n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        end_time = tweet['firstpost_date']\n",
    "    end_time_list_test[i] = end_time\n",
    "print('start_time', start_time_list_test)\n",
    "print('end_time', end_time_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = min(start_time_list_test)\n",
    "end_time = max(end_time_list_test)\n",
    "time_8am = 1422806400\n",
    "time_8pm = 1422849600\n",
    "test_hour_before = math.ceil((time_8am - start_time)/3600.)\n",
    "test_hour_between = math.ceil((time_8pm - time_8am)/3600.)\n",
    "test_hour_after = math.ceil((end_time - time_8am)/3600.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "2.5 [180.5] [178.]\n",
      "1\n",
      "6\n",
      "2.5 [294.8] [203.]\n",
      "2\n",
      "6\n",
      "2.5 [271.4] [211.]\n"
     ]
    }
   ],
   "source": [
    "RMSE_testing = []\n",
    "all_test_before = len(testdata_before)\n",
    "valid_test = [0,1,2]\n",
    "for i in valid_test:\n",
    "    sample = testdata_before[i]\n",
    "    f = io.open(sample, 'r')\n",
    "    print(i)\n",
    "    start_time = start_time_list_test[i]\n",
    "    time_end = end_time_list_test[i]\n",
    "    test_hour_before = math.ceil((time_end - start_time)/3600.)\n",
    "    print(test_hour_before)\n",
    "    test_tweet_features_before = np.zeros([test_hour_before, 9])\n",
    "    test_user_id_before = [[]] * test_hour_before\n",
    "    \n",
    "    # calculate features for model construction\n",
    "    pst_tz = pytz.timezone('US/Pacific')\n",
    "    tweet_0 = json.loads(f.readline())\n",
    "    start_time_1 = tweet_0['firstpost_date']\n",
    "    f.seek(0,0)\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        time_test = tweet['firstpost_date']\n",
    "        #print(time_test)\n",
    "        #print(start_time_1)\n",
    "        # Calculate which hour current tweet belongs to\n",
    "        n = math.ceil((time_test - start_time_1)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "        test_tweet_features_before[(n-1), 0] += 1\n",
    "        test_tweet_features_before[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "        followers = tweet['author']['followers']\n",
    "        test_tweet_features_before[(n-1), 2] += followers\n",
    "        if followers >test_tweet_features_before[(n-1), 3]:\n",
    "            test_tweet_features_before[(n-1), 3] = followers\n",
    "        time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "        test_tweet_features_before[(n-1), 4] = time_of_the_day\n",
    "        test_tweet_features_before[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "        test_tweet_features_before[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "        test_tweet_features_before[(n-1), 7] += tweet['metrics']['impressions']\n",
    "        test_user_id_before[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "    f.close()\n",
    "    #make testset\n",
    "    for t in range(len(test_user_id_before)):\n",
    "        test_tweet_features_before[t, 8] = len(np.unique(all_user_id_before[t]))\n",
    "       \n",
    "    tweet_features_before_test_x = []\n",
    "    tweet_featuers_before_test_y = test_tweet_features_before[test_hour_before-1:,0]\n",
    "    for i in range(1):\n",
    "        tweet_features_before_test_x.append(test_tweet_features_before[i:i+test_hour_before-1,1:])\n",
    "    tweet_features_before_test_x = np.reshape(tweet_features_before_test_x,(len(tweet_features_before_test_x),8*(test_hour_before-1)))\n",
    "    # random forest built and fit to training set\n",
    "    rf = RandomForestRegressor(criterion='mse')\n",
    "    X_train = list(tweet_features_before_set_x)\n",
    "    y_train = list(tweet_featuers_before_set_y)\n",
    "    rf.fit(X_train, y_train)\n",
    "    test_prediction = rf.predict(tweet_features_before_test_x)\n",
    "    RMSE_testing.append(math.sqrt(metrics.mean_squared_error(test_prediction,tweet_featuers_before_test_y)))\n",
    "\n",
    "    print(RMSE_testing[i],test_prediction,tweet_featuers_before_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "211097.5 [293989.5] [82892.]\n",
      "1\n",
      "6\n",
      "211097.5 [310178.2] [37279.]\n",
      "2\n",
      "6\n",
      "211097.5 [249774.5] [2791.]\n"
     ]
    }
   ],
   "source": [
    "#between\n",
    "RMSE_testing_between = []\n",
    "all_test_before = len(testdata_before)\n",
    "valid_test = [0,1,2]\n",
    "for i in valid_test:\n",
    "    sample = testdata_between[i]\n",
    "    f = io.open(sample, 'r')\n",
    "    print(i)\n",
    "    start_time = start_time_list_test[i]\n",
    "    time_end = end_time_list_test[i]\n",
    "    test_hour_between = math.ceil((time_end - start_time)/3600.)\n",
    "    print(test_hour_between)\n",
    "    test_tweet_features_between = np.zeros([test_hour_between, 9])\n",
    "    test_user_id_between = [[]] * test_hour_between\n",
    "    \n",
    "    # calculate features for model construction\n",
    "    pst_tz = pytz.timezone('US/Pacific')\n",
    "    tweet_0 = json.loads(f.readline())\n",
    "    start_time_1 = tweet_0['firstpost_date']\n",
    "    f.seek(0,0)\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        time_test = tweet['firstpost_date']\n",
    "        #print(time_test)\n",
    "        #print(start_time_1)\n",
    "        # Calculate which hour current tweet belongs to\n",
    "        n = math.ceil((time_test - start_time_1)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "        test_tweet_features_between[(n-1), 0] += 1\n",
    "        test_tweet_features_between[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "        followers = tweet['author']['followers']\n",
    "        test_tweet_features_between[(n-1), 2] += followers\n",
    "        if followers >test_tweet_features_between[(n-1), 3]:\n",
    "            test_tweet_features_between[(n-1), 3] = followers\n",
    "        time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "        test_tweet_features_between[(n-1), 4] = time_of_the_day\n",
    "        test_tweet_features_between[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "        test_tweet_features_between[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "        test_tweet_features_between[(n-1), 7] += tweet['metrics']['impressions']\n",
    "        test_user_id_between[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "    f.close()\n",
    "    #make testset\n",
    "    for t in range(len(test_user_id_between)):\n",
    "        test_tweet_features_between[t, 8] = len(np.unique(all_user_id_between[t]))\n",
    "       \n",
    "    tweet_features_between_test_x = []\n",
    "    tweet_featuers_between_test_y = test_tweet_features_between[test_hour_between-1:,0]\n",
    "    for i in range(1):\n",
    "        tweet_features_between_test_x.append(test_tweet_features_between[i:i+test_hour_between-1,1:])\n",
    "    tweet_features_between_test_x = np.reshape(tweet_features_between_test_x,(len(tweet_features_between_test_x),8*(test_hour_between-1)))\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    X_train = list(tweet_features_between_set_x)\n",
    "    y_train = list(tweet_featuers_between_set_y)\n",
    "    rf.fit(X_train, y_train)\n",
    "    test_prediction = rf.predict(tweet_features_between_test_x)\n",
    "    RMSE_testing_between.append(math.sqrt(metrics.mean_squared_error(test_prediction,tweet_featuers_between_test_y)))\n",
    "    print(RMSE_testing_between[i],test_prediction,tweet_featuers_between_test_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "460.4 [984.4] [524.]\n",
      "1\n",
      "6\n",
      "460.4 [31.95] [121.]\n",
      "2\n",
      "6\n",
      "460.4 [49.1] [62.]\n"
     ]
    }
   ],
   "source": [
    "#after\n",
    "RMSE_testing_after = []\n",
    "all_test_before = len(testdata_before)\n",
    "valid_test = [0,1,2]\n",
    "for i in valid_test:\n",
    "    sample = testdata_after[i]\n",
    "    f = io.open(sample, 'r')\n",
    "    print(i)\n",
    "    start_time = start_time_list_test[i]\n",
    "    time_end = end_time_list_test[i]\n",
    "    test_hour_after = math.ceil((time_end - start_time)/3600.)\n",
    "    print(test_hour_after)\n",
    "    test_tweet_features_after = np.zeros([test_hour_after, 9])\n",
    "    test_user_id_after = [[]] * test_hour_after\n",
    "    \n",
    "    # calculate features for model construction\n",
    "    pst_tz = pytz.timezone('US/Pacific')\n",
    "    tweet_0 = json.loads(f.readline())\n",
    "    start_time_1 = tweet_0['firstpost_date']\n",
    "    f.seek(0,0)\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        time_test = tweet['firstpost_date']\n",
    "        #print(time_test)\n",
    "        #print(start_time_1)\n",
    "        # Calculate which hour current tweet belongs to\n",
    "        n = math.ceil((time_test - start_time_1)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "        test_tweet_features_after[(n-1), 0] += 1\n",
    "        test_tweet_features_after[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "        followers = tweet['author']['followers']\n",
    "        test_tweet_features_after[(n-1), 2] += followers\n",
    "        if followers >test_tweet_features_after[(n-1), 3]:\n",
    "            test_tweet_features_after[(n-1), 3] = followers\n",
    "        time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "        test_tweet_features_after[(n-1), 4] = time_of_the_day\n",
    "        test_tweet_features_after[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "        test_tweet_features_after[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "        test_tweet_features_after[(n-1), 7] += tweet['metrics']['impressions']\n",
    "        test_user_id_after[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "    f.close()\n",
    "    #make testset\n",
    "    for t in range(len(test_user_id_after)):\n",
    "        test_tweet_features_after[t, 8] = len(np.unique(all_user_id_after[t]))\n",
    "       \n",
    "    tweet_features_after_test_x = []\n",
    "    tweet_featuers_after_test_y = test_tweet_features_after[test_hour_after-1:,0]\n",
    "    for i in range(1):\n",
    "        tweet_features_after_test_x.append(test_tweet_features_after[i:i+test_hour_after-1,1:])\n",
    "    tweet_features_after_test_x = np.reshape(tweet_features_after_test_x,(len(tweet_features_after_test_x),8*(test_hour_after-1)))\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=20)\n",
    "    X_train = list(tweet_features_after_set_x)\n",
    "    y_train = list(tweet_featuers_after_set_y)\n",
    "    rf.fit(X_train, y_train)\n",
    "    test_prediction = rf.predict(tweet_features_after_test_x)\n",
    "    RMSE_testing_after.append(math.sqrt(metrics.mean_squared_error(test_prediction,tweet_featuers_after_test_y)))\n",
    "    print(RMSE_testing_after[i],test_prediction,tweet_featuers_after_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#special model for sample8_period1.txt\n",
    "tweet_features_before_set_x_ = []\n",
    "tweet_featuers_before_set_y_ = all_tweet_features_before[4:,0]\n",
    "\n",
    "for i in range(all_hour_before-4):\n",
    "    tweet_features_before_set_x_.append(all_tweet_features_before[i:i+4,1:])\n",
    "tweet_features_before_set_x_=np.reshape(tweet_features_before_set_x_,(len(tweet_features_before_set_x_),32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5\n",
      "37.6 [49.6] [12.]\n"
     ]
    }
   ],
   "source": [
    "RMSE_testing = []\n",
    "all_test_before = len(testdata_before)\n",
    "valid_test = [3]\n",
    "for i in valid_test:\n",
    "    sample = testdata_before[i]\n",
    "    f = io.open(sample, 'r')\n",
    "    print(i)\n",
    "    start_time = start_time_list_test[i]\n",
    "    time_end = end_time_list_test[i]\n",
    "    test_hour_before = math.ceil((time_end - start_time)/3600.)\n",
    "    print(test_hour_before)\n",
    "    test_tweet_features_before = np.zeros([test_hour_before, 9])\n",
    "    test_user_id_before = [[]] * test_hour_before\n",
    "    \n",
    "    # calculate features for model construction\n",
    "    pst_tz = pytz.timezone('US/Pacific')\n",
    "    tweet_0 = json.loads(f.readline())\n",
    "    start_time_1 = tweet_0['firstpost_date']\n",
    "    f.seek(0,0)\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "        time_test = tweet['firstpost_date']\n",
    "        #print(time_test)\n",
    "        #print(start_time_1)\n",
    "        # Calculate which hour current tweet belongs to\n",
    "        n = math.ceil((time_test - start_time_1)/3600.)\n",
    "            # Update value of features for corresponding hour \n",
    "        test_tweet_features_before[(n-1), 0] += 1\n",
    "        test_tweet_features_before[(n-1), 1] += tweet['metrics']['citations']['total']\n",
    "        followers = tweet['author']['followers']\n",
    "        test_tweet_features_before[(n-1), 2] += followers\n",
    "        if followers >test_tweet_features_before[(n-1), 3]:\n",
    "            test_tweet_features_before[(n-1), 3] = followers\n",
    "        time_of_the_day = int(datetime.datetime.fromtimestamp(tweet['firstpost_date'], pst_tz).strftime(\"%H\"))\n",
    "        test_tweet_features_before[(n-1), 4] = time_of_the_day\n",
    "        test_tweet_features_before[(n-1), 5] += tweet['metrics']['ranking_score']\n",
    "        test_tweet_features_before[(n-1), 6] += tweet['tweet']['favorite_count']\n",
    "        test_tweet_features_before[(n-1), 7] += tweet['metrics']['impressions']\n",
    "        test_user_id_before[(n-1)].append(tweet['tweet']['user']['id'])\n",
    "    f.close()\n",
    "    #make testset\n",
    "    for t in range(len(test_user_id_before)):\n",
    "        test_tweet_features_before[t, 8] = len(np.unique(all_user_id_before[t]))\n",
    "       \n",
    "    tweet_features_before_test_x = []\n",
    "    tweet_featuers_before_test_y = test_tweet_features_before[test_hour_before-1:,0]\n",
    "    for i in range(1):\n",
    "        tweet_features_before_test_x.append(test_tweet_features_before[i:i+test_hour_before-1,1:])\n",
    "    tweet_features_before_test_x = np.reshape(tweet_features_before_test_x,(len(tweet_features_before_test_x),8*(test_hour_before-1)))\n",
    "    # random forest built and fit to training set\n",
    "    rf = RandomForestRegressor(n_estimators=10,criterion='mse')\n",
    "    X_train = list(tweet_features_before_set_x_)\n",
    "    y_train = list(tweet_featuers_before_set_y_)\n",
    "    rf.fit(X_train, y_train)\n",
    "    test_prediction = rf.predict(tweet_features_before_test_x)\n",
    "    RMSE_testing.append(math.sqrt(metrics.mean_squared_error(test_prediction,tweet_featuers_before_test_y)))\n",
    "\n",
    "    print(RMSE_testing[i],test_prediction,tweet_featuers_before_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
